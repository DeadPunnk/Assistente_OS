# ğŸ¤– Assistente_os: RAG com Processamento Local
Este projeto foi desenvolvido para solucionar a fragmentaÃ§Ã£o de informaÃ§Ãµes em contextos de projetos complexos. Utilizando a arquitetura RAG (Retrieval-Augmented Generation), o assistente permite interagir com atas de reuniÃ£o, documentaÃ§Ãµes e evidÃªncias tÃ©cnicas em formatos heterogÃªneos (PDF, DOCX, TXT), garantindo respostas fundamentadas e com rastreabilidade de fontes.

## ğŸŒŸ Diferenciais TÃ©cnicos
Privacidade Total: Processamento 100% local via Ollama. Nenhum dado sensÃ­vel sai da infraestrutura.

Busca SemÃ¢ntica: UtilizaÃ§Ã£o de Embeddings do HuggingFace para capturar o contexto alÃ©m das palavras-chave.

Rastreabilidade (Lineage): Cada resposta acompanha a citaÃ§Ã£o do documento original utilizado como fonte.

Interface Intuitiva: Chat dinÃ¢mico desenvolvido em Streamlit focado na experiÃªncia do analista.

## ğŸ—ï¸ Arquitetura do Sistema
IngestÃ£o: Carregamento de documentos heterogÃªneos da OneDrive/Local.

Processamento: FragmentaÃ§Ã£o inteligente com RecursiveCharacterTextSplitter.

VetorizaÃ§Ã£o: GeraÃ§Ã£o de vetores via HuggingFaceEmbeddings.

Storage: PersistÃªncia local em banco vetorial ChromaDB.

RecuperaÃ§Ã£o: Chain de recuperaÃ§Ã£o customizada (LCEL) integrada ao modelo Qwen 2.5.

## ğŸš€ Como Executar

PrÃ©-requisitos
Python 3.10 ou superior

Ollama instalado e rodando.

Modelo Qwen carregado: ollama pull qwen3:4b (ou a versÃ£o de sua preferÃªncia).

InstalaÃ§Ã£o
Clone o repositÃ³rio:

Bash

git clone https://github.com/deadpunnk/assistente_os.git
cd assistente_os
Crie e ative um ambiente virtual:

Bash

python -m venv venv
source venv/bin/activate  # Windows: .\venv\Scripts\activate
Instale as dependÃªncias:

Bash

pip install -r requirements.txt
Configure o arquivo .env com sua chave de API (opcional se usar apenas Ollama):

ExecuÃ§Ã£o
Inicie a interface do Streamlit:

Bash

streamlit run app.py
ğŸ› ï¸ Tecnologias Utilizadas
LangChain: OrquestraÃ§Ã£o de componentes de LLM.

ChromaDB: Banco de dados vetorial de alta performance.

HuggingFace: Modelos de Embedding locais.

Ollama: Runtime para execuÃ§Ã£o de LLMs open-source.

Streamlit: Framework para interfaces de dados.

ğŸ“‚ Estrutura de Pastas
Plaintext

â”œâ”€â”€ data/               # Documentos originais (PDF, DOCX, TXT)
â”œâ”€â”€ db_chroma/          # PersistÃªncia do banco vetorial (gerado automaticamente)
â”œâ”€â”€ app.py              # Interface Streamlit e lÃ³gica RAG
â”œâ”€â”€ requirements.txt    # DependÃªncias do projeto
â””â”€â”€ .env                # VariÃ¡veis de ambiente